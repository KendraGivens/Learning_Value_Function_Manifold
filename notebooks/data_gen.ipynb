{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "701c8429-fbbc-4e99-98a2-f60a5df8b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3773d86-835e-47f0-a558-88790d8fdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7936a95-672f-4024-a122-c8dbf570b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps x,t,mu to u (pde solution)\n",
    "def burgers_exact_eqn(x, t, mu):\n",
    "    pi = torch.pi\n",
    "    e1 = torch.exp(-(pi**2)*t/mu)\n",
    "    e4 = torch.exp(-(4*pi**2)*t/mu)\n",
    "    \n",
    "    num = 0.25 * e1 * torch.sin(pi*x) + e4 * torch.sin(2*pi*x)\n",
    "    den = 1.0 + 0.25 * e1 * torch.cos(pi*x) + 0.5 * e4 * torch.cos(2*pi*x)\n",
    "\n",
    "    return (2*pi/mu)*(num/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "440c4dea-55c8-4526-aea2-438cadbec9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_burgers_solution_grid(mu_values, n_x, n_t, T_final=1.0):\n",
    "    # create range of values as vectors\n",
    "    x_axis = torch.linspace(0.0, 2.0, n_x)          # (nx,)\n",
    "    t_axis = torch.linspace(0.0, T_final, n_t + 1)  # (nt+1,)\n",
    "    mu_axis = torch.tensor(mu_values)                # (nmu,)\n",
    "\n",
    "    # create full grid across all space, time, parameters\n",
    "    X_grid = x_axis[None, None, :].expand(mu_axis.shape[0], t_axis.shape[0], x_axis.shape[0])\n",
    "    T_grid = t_axis[None, :, None].expand_as(X_grid)\n",
    "    Mu_grid = mu_axis[:, None, None].expand_as(X_grid)\n",
    "\n",
    "    # evaluate solution on full grid\n",
    "    u_grid = burgers_exact_eqn(X_grid, T_grid, Mu_grid)\n",
    "\n",
    "    # enforce boundary conditions\n",
    "    u_grid[:, :, 0]  = 0.0\n",
    "    u_grid[:, :, -1] = 0.0\n",
    "\n",
    "    return x_axis, t_axis, mu_axis, u_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "777c4ee7-2c48-4d8f-802b-1a177b2bbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples (x, t, mu) with target u from the solution grid\n",
    "class BurgersExactDataset(Dataset):\n",
    "    def __init__(self, x_axis, t_axis, mu_axis, u_grid, n_samples=200000):\n",
    "        super().__init__()\n",
    "        # coordinate axes\n",
    "        self.x_axis = x_axis\n",
    "        self.t_axis = t_axis\n",
    "        self.mu_axis = mu_axis\n",
    "\n",
    "        # solution field\n",
    "        self.u_grid = u_grid\n",
    "\n",
    "        # grid sizes\n",
    "        self.n_mu, self.n_tp1, self.n_x = u_grid.shape\n",
    "\n",
    "        self.n_samples = int(n_samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # sample random axis indices\n",
    "        i_mu = torch.randint(0, self.n_mu, (1,)).item()\n",
    "        i_t = torch.randint(1, self.n_tp1, (1,)).item()\n",
    "        i_x = torch.randint(0, self.n_x, (1,)).item()\n",
    "\n",
    "        # coordinates at those indices\n",
    "        x_coord = self.x_axis[i_x]\n",
    "        t_coord = self.t_axis[i_t]\n",
    "        mu_val = self.mu_axis[i_mu]\n",
    "\n",
    "        # target solution value\n",
    "        y = self.u_grid[i_mu, i_t, i_x]\n",
    "\n",
    "        return x_coord, t_coord, mu_val, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b36c2c3-2401-4cc6-8d9b-75aebb9a682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurgersPhysicsDataset(Dataset):\n",
    "    def __init__(self, mus, n_samples):\n",
    "        super().__init__()\n",
    "        self.mus = torch.tensor(mus, device=device)\n",
    "        self.n_mu = len(self.mus)\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i_mu = torch.randint(0, self.n_mu, (1,)).item()\n",
    "        mu_val = self.mus[i_mu]\n",
    "\n",
    "        eps = 1e-6\n",
    "        x_coord = torch.clamp(torch.rand(())*2.0, eps, 2.0-eps)\n",
    "        t_coord = torch.clamp(torch.rand(()), eps, 1.0)\n",
    "\n",
    "        return x_coord, t_coord, mu_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e485465f-6183-4d0f-a403-bed800954c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_train = [20, 30]\n",
    "mu_test = [15, 25]\n",
    "mu_all = sorted(mu_train+mu_test)\n",
    "n_x = 16\n",
    "n_t = 100\n",
    "T_f = 1.0\n",
    "x_axis, t_axis, mu_axis, u_grid = generate_burgers_solution_grid(mu_train, n_x, n_t, T_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d22e19be-f526-4fdf-8be6-ffbbd6c7c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_train_dataset = BurgersExactDataset(x_axis, t_axis, mu_axis, u_grid, n_samples=1000)\n",
    "exact_train_loader = DataLoader(exact_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "physics_train_dataset = BurgersPhysicsDataset(mu_all, n_samples=1000)\n",
    "physics_train_loader = DataLoader(physics_train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0def79b9-0182-45b2-abde-17fe6811a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass inputs through fourier features\n",
    "class FourierFeatures(nn.Module):\n",
    "    def __init__(self, n_freqs=16, max_freq=10.0):\n",
    "        super().__init__()\n",
    "        freqs = torch.linspace(1.0, max_freq, n_freqs)\n",
    "        self.register_buffer(\"freqs\", freqs)\n",
    "\n",
    "    def forward(self, x): \n",
    "        if x.dim() == 1:\n",
    "            x = x[:, None]\n",
    "        w = x * self.freqs[None, :] * torch.pi # (B, n_freq)\n",
    "        return torch.cat([torch.sin(w), torch.cos(w)], dim=-1) # (B, 2*n_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad7e82b7-4dd8-4a96-90a9-50b35ed40be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder that takes in x and alpha and outputs u\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=10, n_freqs=16, max_freq=10.0, hidden=128, n_hidden_layers=3):\n",
    "        super().__init__()\n",
    "        self.ff = FourierFeatures(n_freqs=n_freqs, max_freq=max_freq)\n",
    "        dim = 2 * n_freqs + latent_dim\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(n_hidden_layers):\n",
    "            layers += [nn.Linear(dim, hidden), nn.Tanh()]\n",
    "            dim = hidden\n",
    "        layers += [nn.Linear(dim, 1)]\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        phi_x = self.ff(x) # (B, 2*n_freq)\n",
    "        inputs = torch.cat([phi_x, alpha], dim=-1)\n",
    "        u = self.model(inputs) # (B, 1)\n",
    "        return u.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6acce95-a1b5-47de-8b68-cc72dd821bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameterized neural ode that takes in mu, alpha and t and outputs time derivative of alpha\n",
    "class PNODEFunc(nn.Module):\n",
    "    def __init__(self, latent_dim=10, hidden=128, n_hidden_layers=2):\n",
    "        super().__init__()\n",
    "        dim = latent_dim + 2 # alpha + t + mu\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(n_hidden_layers):\n",
    "            layers += [nn.Linear(dim, hidden), nn.Tanh()]\n",
    "            dim = hidden\n",
    "        layers += [nn.Linear(dim, latent_dim)]\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, alpha, t, mu):\n",
    "        B = alpha.shape[0]\n",
    "        t_col = t.expand(B, 1)\n",
    "        mu_col = mu.view(B, 1)\n",
    "        inputs = torch.cat([alpha, t_col, mu_col], dim=-1)\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "495c2040-51a2-4b2c-b4c4-30d72e5bca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNODE(nn.Module):\n",
    "    def __init__(self, func: PNODEFunc, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def solve_alpha(self, t_eval, mu, alpha0=None, method=\"rk4\"):\n",
    "        B = mu.shape[0]\n",
    "        \n",
    "        # initalize alpha\n",
    "        if alpha0 is None:\n",
    "            alpha0 = torch.zeros(B, self.latent_dim, device=mu.device)\n",
    "\n",
    "        def f_wrapped(t, alpha):\n",
    "            return self.func(alpha, t, mu)\n",
    "\n",
    "        alpha_trajectory = odeint(f_wrapped, alpha0, t_eval, method=method)\n",
    "        return alpha_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a58a6196-9033-47fb-ac20-4975ac3063fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_xt(x, t):\n",
    "    return x * (2.0-x) * t\n",
    "    \n",
    "def u_constrained(decoder, x, t, alpha):\n",
    "    return phi_xt(x, t) * decoder(x, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07da569f-ac01-4e82-9ccf-217f45645b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loss(model, batch):\n",
    "    x, t, mu, y = batch\n",
    "    pred = model(x, t, mu)\n",
    "    return torch.mean((pred-y)**2)\n",
    "\n",
    "def physics_loss(model, batch):\n",
    "    x, t, mu = batch\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    t = t.clone().detach().requires_grad_(True)\n",
    "    mu = mu.clone().detach()\n",
    "\n",
    "    u = model(x, t, mu)  \n",
    "\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    \n",
    "    residual = u_t + u * u_x - (1.0/mu) * u_xx\n",
    "\n",
    "    return torch.mean(residual**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f787fb48-c3cb-4720-8f7c-6bb26c93112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNFROM(nn.Module):\n",
    "    def __init__(self, decoder: Decoder, pnode: PNODE):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder\n",
    "        self.pnode = pnode\n",
    "\n",
    "    def forward(self, x, t, mu):\n",
    "        B = x.shape[0]\n",
    "        u_out = []\n",
    "        for i in range(B):\n",
    "            ti  = t[i:i+1]\n",
    "            mui = mu[i:i+1]\n",
    "            t_eval = torch.cat([torch.zeros_like(ti), ti], dim=0)\n",
    "            alpha_trajectory = self.pnode.solve_alpha(t_eval, mui)  \n",
    "            alpha_t = alpha_trajectory[-1, 0, :].unsqueeze(0)\n",
    "            ui = u_constrained(self.decoder, x[i:i+1], ti, alpha_t)\n",
    "            u_out.append(ui)\n",
    "        return torch.cat(u_out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eee1fab1-8fe7-4de4-aa33-9665c993abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(L.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3, mode=\"data\"):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.mode = mode\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if self.mode == \"data\":\n",
    "            loss = data_loss(self.model, batch) \n",
    "        else:\n",
    "            loss = physics_loss(self.model, batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae1dd1bc-b528-4835-88e7-d93f7a0538a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10\n",
    "max_epochs = 10\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b63900e-9919-45bb-b832-9712080e075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(latent_dim=latent_dim)\n",
    "pnode_func = PNODEFunc(latent_dim=latent_dim)\n",
    "pnode = PNODE(pnode_func, latent_dim=latent_dim)\n",
    "cnf = CNFROM(decoder, pnode)\n",
    "model = Model(cnf, mode=\"data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33bfe90b-31dd-485c-ab27-97b83c1043b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | CNFROM | 58.1 K | train\n",
      "-----------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/kendra/miniconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kendra/miniconda3/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a295978d9dfd45e691a005a2156ba930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "data_trainer = L.Trainer(accelerator=\"gpu\", devices=1, max_epochs=max_epochs)\n",
    "data_trainer.fit(model, exact_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "147f48e1-243a-4247-8aa3-a62b1ca9b9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | CNFROM | 58.1 K | train\n",
      "-----------------------------------------\n",
      "19.5 K    Trainable params\n",
      "38.7 K    Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/kendra/miniconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kendra/miniconda3/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8882e155201f4a2696ead537f396ae53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in model.model.decoder.parameters():\n",
    "    p.requires_grad = False\n",
    "model.mode = \"physics\"\n",
    "physics_trainer = L.Trainer(accelerator=\"gpu\", devices=1, max_epochs=max_epochs)\n",
    "physics_trainer.fit(model, physics_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d942e-7f08-4d7f-8de6-b5c0f26177aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
