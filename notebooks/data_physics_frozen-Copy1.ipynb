{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89077b00-e013-429a-b130-3e1570dd4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from lightning.pytorch.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b4586d-6a72-41bc-aebd-e7bdcbc6e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8def4be3-0572-486d-b632-b3fc053efc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps x,t,mu to u (pde solution)\n",
    "def burgers_exact_eqn(x, t, mu):\n",
    "    pi = torch.pi\n",
    "    e1 = torch.exp(-(pi**2)*t/mu)\n",
    "    e4 = torch.exp(-(4*pi**2)*t/mu)\n",
    "    \n",
    "    num = 0.25 * e1 * torch.sin(pi*x) + e4 * torch.sin(2*pi*x)\n",
    "    den = 1.0 + 0.25 * e1 * torch.cos(pi*x) + 0.5 * e4 * torch.cos(2*pi*x)\n",
    "\n",
    "    return (2*pi/mu)*(num/den)\n",
    "\n",
    "def generate_burgers_solution_grid(mu_values, n_x, n_t, T_final=1.0):\n",
    "    # create range of values as vectors\n",
    "    x_axis = torch.linspace(0.0, 2.0, n_x)          # (nx,)\n",
    "    t_axis = torch.linspace(0.0, T_final, n_t + 1)  # (nt+1,)\n",
    "    mu_axis = torch.tensor(mu_values)                # (nmu,)\n",
    "\n",
    "    # create full grid across all space, time, parameters\n",
    "    X_grid = x_axis[None, None, :].expand(mu_axis.shape[0], t_axis.shape[0], x_axis.shape[0])\n",
    "    T_grid = t_axis[None, :, None].expand_as(X_grid)\n",
    "    Mu_grid = mu_axis[:, None, None].expand_as(X_grid)\n",
    "\n",
    "    # evaluate solution on full grid\n",
    "    u_grid = burgers_exact_eqn(X_grid, T_grid, Mu_grid)\n",
    "\n",
    "    # enforce boundary conditions\n",
    "    u_grid[:, :, 0]  = 0.0\n",
    "    u_grid[:, :, -1] = 0.0\n",
    "\n",
    "    return x_axis, t_axis, mu_axis, u_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1a875b-bb79-42da-bf44-c01c0390135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples (x, t, mu) with target u from the solution grid\n",
    "class BurgersExactDataset(Dataset):\n",
    "    def __init__(self, x_axis, t_axis, mu_axis, u_grid, n_samples=200000):\n",
    "        super().__init__()\n",
    "        # coordinate axes\n",
    "        self.x_axis = x_axis\n",
    "        self.t_axis = t_axis\n",
    "        self.mu_axis = mu_axis\n",
    "\n",
    "        # solution field\n",
    "        self.u_grid = u_grid\n",
    "\n",
    "        # grid sizes\n",
    "        self.n_mu, self.n_tp1, self.n_x = u_grid.shape\n",
    "\n",
    "        self.n_samples = int(n_samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # sample random axis indices\n",
    "        i_mu = torch.randint(0, self.n_mu, (1,)).item()\n",
    "        i_t = torch.randint(1, self.n_tp1, (1,)).item()\n",
    "        i_x = torch.randint(0, self.n_x, (1,)).item()\n",
    "\n",
    "        # coordinates at those indices\n",
    "        x_coord = self.x_axis[i_x]\n",
    "        t_coord = self.t_axis[i_t]\n",
    "        mu_val = self.mu_axis[i_mu]\n",
    "\n",
    "        # target solution value\n",
    "        y = self.u_grid[i_mu, i_t, i_x]\n",
    "\n",
    "        return x_coord, t_coord, mu_val, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509cd445-bcde-4d09-a8b8-435f03d976f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurgersPhysicsDataset(Dataset):\n",
    "    def __init__(self, mus, n_samples):\n",
    "        super().__init__()\n",
    "        self.mus = torch.tensor(mus)\n",
    "        self.n_mu = len(self.mus)\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i_mu = torch.randint(0, self.n_mu, (1,)).item()\n",
    "        mu_val = self.mus[i_mu]\n",
    "\n",
    "        eps = 1e-6\n",
    "        x_coord = torch.clamp(torch.rand(())*2.0, eps, 2.0-eps)\n",
    "        t_coord = torch.clamp(torch.rand(()), eps, 1.0)\n",
    "\n",
    "        return x_coord, t_coord, mu_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184d0200-94ea-41ea-8945-14691eec592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass inputs through fourier features\n",
    "class FourierFeatures(nn.Module):\n",
    "    def __init__(self, n_freqs=16, max_freq=10.0):\n",
    "        super().__init__()\n",
    "        freqs = torch.linspace(1.0, max_freq, n_freqs)\n",
    "        self.register_buffer(\"freqs\", freqs)\n",
    "\n",
    "    def forward(self, x): \n",
    "        if x.dim() == 1:\n",
    "            x = x[:, None]\n",
    "        w = x * self.freqs[None, :] * torch.pi # (B, n_freq)\n",
    "        return torch.cat([torch.sin(w), torch.cos(w)], dim=-1) # (B, 2*n_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e4d892-e8b9-475c-8292-5e6649246901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder that takes in x and alpha and outputs u\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=10, n_freqs=16, max_freq=10.0, hidden=128, n_hidden_layers=3):\n",
    "        super().__init__()\n",
    "        self.ff = FourierFeatures(n_freqs=n_freqs, max_freq=max_freq)\n",
    "        dim = 2 * n_freqs + latent_dim\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(n_hidden_layers):\n",
    "            layers += [nn.Linear(dim, hidden), nn.Tanh()]\n",
    "            dim = hidden\n",
    "        layers += [nn.Linear(dim, 1)]\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        phi_x = self.ff(x) # (B, 2*n_freq)\n",
    "        inputs = torch.cat([phi_x, alpha], dim=-1)\n",
    "        u = self.model(inputs) # (B, 1)\n",
    "        return u.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197dbda1-709e-45d6-893f-b980a4e396d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameterized neural ode that takes in mu, alpha and t and outputs time derivative of alpha\n",
    "class PNODEFunc(nn.Module):\n",
    "    def __init__(self, latent_dim=10, hidden=128, n_hidden_layers=2):\n",
    "        super().__init__()\n",
    "        dim = latent_dim + 2 # alpha + t + mu\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(n_hidden_layers):\n",
    "            layers += [nn.Linear(dim, hidden), nn.Tanh()]\n",
    "            dim = hidden\n",
    "        layers += [nn.Linear(dim, latent_dim)]\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, alpha, t, mu):\n",
    "        B = alpha.shape[0]\n",
    "        t_col = t.expand(B, 1)\n",
    "        mu_col = mu.view(B, 1)\n",
    "        inputs = torch.cat([alpha, t_col, mu_col], dim=-1)\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a552508f-061c-41fc-af09-e527e953e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNODE(nn.Module):\n",
    "    def __init__(self, func: PNODEFunc, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def forward(self, t, alpha, mu):\n",
    "        B = alpha.shape[0]\n",
    "        t_vec = t.expand(B, 1)\n",
    "        if mu.dim() == 1:\n",
    "            mu = mu.unsqueeze(-1)\n",
    "        return self.func(alpha, t_vec, mu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22c1b98-b411-4d4b-aa53-0bc254e87952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_xt(x, t):\n",
    "    return x * (2.0-x) * t\n",
    "\n",
    "def g_ic(x, t, mu):\n",
    "    return burgers_exact_eqn(x, torch.zeros_like(t), mu)\n",
    "\n",
    "def u_constrained(decoder, x, t, alpha, mu):\n",
    "    return g_ic(x, t, mu) + phi_xt(x, t) * decoder(x, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2f4161-435b-4773-b446-a4e8d8199ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loss_fn(model, batch):\n",
    "    x, t, mu, y = batch\n",
    "    pred = model(x, t, mu)\n",
    "    return torch.mean((pred-y)**2)\n",
    "\n",
    "def physics_loss_fn(model, batch):\n",
    "    x, t, mu = batch\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    t = t.clone().detach().requires_grad_(True)\n",
    "    mu = mu.clone().detach()\n",
    "\n",
    "    alpha, f_theta = model.get_latents(t, mu)\n",
    "    D = model.decoder(x, alpha)\n",
    "    phi = phi_xt(x, t)\n",
    "    g = g_ic(x, t, mu)\n",
    "\n",
    "    dt_phi = torch.autograd.grad(phi.sum(), t, create_graph=True)[0]\n",
    "    dt_g = torch.zeros_like(t)\n",
    "\n",
    "    u_t_explicit = dt_g + D * dt_phi\n",
    "    grad_alpha_D = torch.autograd.grad(D.sum(), alpha, create_graph=True)[0]\n",
    "    chain_rule_term = (grad_alpha_D * f_theta).sum(dim=1)\n",
    "     \n",
    "    u_t_implicit = phi * chain_rule_term\n",
    "    u_t = u_t_explicit + u_t_implicit\n",
    "    u_full = g + phi * D\n",
    "    u_x = torch.autograd.grad(u_full.sum(), x, create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0]\n",
    "\n",
    "    residual = u_t + u_full * u_x - (1.0/mu) * u_xx\n",
    "\n",
    "    return torch.mean(residual**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606240a8-4c8d-4049-969c-cf21cdfcfb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNFROM(nn.Module):\n",
    "    def __init__(self, decoder: Decoder, pnode: PNODE):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder\n",
    "        self.pnode = pnode\n",
    "\n",
    "    def get_latents(self, t, mu, T=1.0, steps=101):\n",
    "        device = mu.device\n",
    "        \n",
    "        t_grid = torch.linspace(0.0, T, steps, device=device)\n",
    "        alpha0 = torch.zeros(mu.shape[0], self.pnode.latent_dim, device=device)\n",
    "\n",
    "        def func(t_, a_):\n",
    "            return self.pnode(t_, a_, mu)\n",
    "        alpha_trajectory = odeint(func, alpha0, t_grid, method=\"rk4\")\n",
    "\n",
    "        # interpolate to t\n",
    "        dt = t_grid[1] - t_grid[0]\n",
    "        indices = torch.floor(t/dt).long().clamp(0, steps-2)\n",
    "        trajectory = alpha_trajectory.permute(1, 0, 2)\n",
    "        batch_ids = torch.arange(t.shape[0], device=device)\n",
    "        alpha_start = trajectory[batch_ids, indices]\n",
    "        alpha_end = trajectory[batch_ids, indices+1]\n",
    "\n",
    "        t_start = t_grid[indices]\n",
    "        ratio = ((t-t_start)/dt).unsqueeze(-1)\n",
    "        alpha_interp = alpha_start + ratio * (alpha_end - alpha_start)\n",
    "\n",
    "        f_theta = self.pnode(t.unsqueeze(-1), alpha_interp, mu)\n",
    "\n",
    "        return alpha_interp, f_theta\n",
    "\n",
    "    def forward(self, x, t, mu):\n",
    "        alpha, _ = self.get_latents(t, mu)   \n",
    "        u = u_constrained(self.decoder, x, t, alpha, mu) \n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2170c86d-8326-46b7-aa0c-5f51119637f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(L.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3, mode=\"data\"):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.mode = mode\n",
    "\n",
    "        self.loss_hist = {\"data\": [], \"physics\": []}\n",
    "        self.epoch_loss_hist = {\"data\": [], \"physics\": []}\n",
    "        self.epoch_losses = []\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if self.mode == \"data\":\n",
    "            loss = data_loss_fn(self.model, batch) \n",
    "        else:\n",
    "            loss = physics_loss_fn(self.model, batch)\n",
    "            \n",
    "        self.log(f\"train_loss_{self.mode}\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.epoch_losses.append(loss.detach())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.mode == \"data\":\n",
    "            return torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        else:\n",
    "            return torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if len(self.epoch_losses) > 0:\n",
    "            mean_loss = torch.stack(self.epoch_losses).mean().item()\n",
    "            self.epoch_loss_hist[self.mode].append(mean_loss)\n",
    "        self.epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eda22e94-b37d-4d0a-9876-912c929bee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_train = [20.0, 30.0, 40.0]\n",
    "mu_test  = [15.0, 25.0]\n",
    "mu_all = sorted(mu_train+mu_test)\n",
    "n_x = 64\n",
    "n_t = 100\n",
    "T_f = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b60e0f-36c0-4729-813d-c944944a4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis, t_axis, mu_axis, u_grid = generate_burgers_solution_grid(mu_train, n_x, n_t, T_f)\n",
    "\n",
    "exact_train_dataset = BurgersExactDataset(x_axis, t_axis, mu_axis, u_grid, n_samples=50000)\n",
    "exact_train_loader = DataLoader(exact_train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "physics_train_dataset = BurgersPhysicsDataset(mu_all, n_samples=50000)\n",
    "physics_train_loader = DataLoader(physics_train_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf400b3-67c2-4179-99b6-525da9d669cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10\n",
    "max_epochs_data = 500\n",
    "max_epochs_physics = 500\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a3b4a8-85fc-48bd-8c6d-03a397424514",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(latent_dim=latent_dim)\n",
    "pnode_func = PNODEFunc(latent_dim=latent_dim)\n",
    "pnode = PNODE(pnode_func, latent_dim=latent_dim)\n",
    "cnf = CNFROM(decoder, pnode)\n",
    "model = Model(cnf, mode=\"data\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9de1e-9d73-46b4-9cf8-beae8ad8325b",
   "metadata": {},
   "source": [
    "# Data + Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c560ed4-8ed0-4624-b955-8ab565349081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | CNFROM | 58.1 K | train\n",
      "-----------------------------------------\n",
      "58.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 K    Total params\n",
      "0.232     Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/kendra/miniconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e78f8a72b4144f1889255c91c55225d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.mode = \"data\"\n",
    "L.Trainer(accelerator=\"gpu\", devices=1, max_epochs=max_epochs_data).fit(model, exact_train_loader)\n",
    "\n",
    "pretrained_cnf = copy.deepcopy(model)\n",
    "\n",
    "for p in model.model.decoder.parameters():\n",
    "    p.requires_grad = False\n",
    "model.mode = \"physics\"\n",
    "L.Trainer(accelerator=\"gpu\", devices=1, max_epochs=max_epochs_physics).fit(model, physics_train_loader)\n",
    "\n",
    "finetuned_cnf = copy.deepcopy(model)\n",
    "\n",
    "data_losses = model.loss_hist[\"data\"]\n",
    "phys_losses = model.loss_hist[\"physics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db35da3-c3d7-4154-81f4-b10f6a3f2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loss = model.epoch_loss_hist[\"data\"]\n",
    "physics_loss = model.epoch_loss_hist[\"physics\"]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(data_loss, label=\"Data Loss\")\n",
    "plt.plot(np.arange(len(data_loss), len(data_loss)+len(physics_loss)),physics_loss, label=\"Physics Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6885ca-cb00-45e0-8297-40cbd7bbef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_heatmap_compare(cnf_pre, cnf_fin, mu0=20.0, n_x=128, n_t=128, T=1.0):\n",
    "    x = torch.linspace(0.0, 2.0, n_x, device=next(cnf_pre.parameters()).device)\n",
    "    t = torch.linspace(0.0, T, n_t, device=x.device)\n",
    "    X, Tt = torch.meshgrid(x, t, indexing=\"xy\")\n",
    "    x_flat = X.reshape(-1)\n",
    "    t_flat = Tt.reshape(-1)\n",
    "    mu_flat = torch.full_like(x_flat, float(mu0))\n",
    "\n",
    "    u_true = burgers_exact_eqn(X, Tt, torch.full_like(X, float(mu0)))\n",
    "    u_pre = cnf_pre(x_flat, t_flat, mu_flat).reshape_as(X)\n",
    "    u_fin = cnf_fin(x_flat, t_flat, mu_flat).reshape_as(X)\n",
    "\n",
    "    err_pre = (u_pre - u_true).abs()\n",
    "    err_fin = (u_fin - u_true).abs()\n",
    "    def rel_L2(u_pred, u_true):\n",
    "        return (torch.norm(u_pred - u_true) / (torch.norm(u_true) + 1e-12)).item()\n",
    "\n",
    "    rel_pre = rel_L2(u_pre, u_true)\n",
    "    rel_fin = rel_L2(u_fin, u_true)\n",
    "    u_min = torch.min(torch.stack([u_true.min(), u_pre.min(), u_fin.min()])).item()\n",
    "    u_max = torch.max(torch.stack([u_true.max(), u_pre.max(), u_fin.max()])).item()\n",
    "    e_min = 0.0\n",
    "    e_max = torch.max(torch.stack([err_pre.max(), err_fin.max()])).item()\n",
    "\n",
    "    def show(ax, M, title, vmin=None, vmax=None):\n",
    "        im = ax.imshow(\n",
    "            M.T.detach().cpu(),\n",
    "            origin=\"lower\",\n",
    "            aspect=\"auto\",\n",
    "            extent=[x.min().item(), x.max().item(), t.min().item(), t.max().item()],\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.set_xlabel(\"Space x\")\n",
    "        ax.set_ylabel(\"Time t\")\n",
    "        ax.set_title(title)\n",
    "        return im\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(14, 7))\n",
    "\n",
    "    im0 = show(axs[0,0], u_true, \"True u(x,t)\", vmin=u_min, vmax=u_max)\n",
    "    im1 = show(axs[0,1], u_pre,  f\"Pretrained Prediction\\nRel L2={rel_pre:.3f}\", vmin=u_min, vmax=u_max)\n",
    "    im2 = show(axs[0,2], u_fin,  f\"Finetuned Prediction\\nRel L2={rel_fin:.3f}\", vmin=u_min, vmax=u_max)\n",
    "\n",
    "    axs[1,0].axis(\"off\")\n",
    "    im4 = show(axs[1,1], err_pre, \"Pretrained Error\", vmin=e_min, vmax=e_max)\n",
    "    im5 = show(axs[1,2], err_fin, \"Finetuned Error\", vmin=e_min, vmax=e_max)\n",
    "\n",
    "    fig.colorbar(im0, ax=axs[0,:], fraction=0.02)\n",
    "    fig.colorbar(im4, ax=axs[1,1:], fraction=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e6a45-bcfb-4993-b12f-3635fe6fc384",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 20.0\n",
    "cnf_pre = pretrained_cnf.model\n",
    "cnf_fin = finetuned_cnf.model\n",
    "plot_heatmap_compare(cnf_pre, cnf_fin, mu0=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39477d-084d-4db2-8076-b16168a2376d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
